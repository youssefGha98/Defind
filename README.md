# DefInd ğŸ”

**DefInd** is a high-performance, Python-native DeFi log fetcher designed for efficient extraction and processing of Ethereum blockchain event data. Built specifically for DeFi protocols, it provides resumable, concurrent data fetching with dynamic column projections and universal storage format.

## âœ¨ Features

- **ğŸš€ High Performance**: Async/concurrent fetching with configurable parallelism
- **ğŸ”„ Resumable Operations**: Live manifest system for fault-tolerant data collection
- **ğŸ“Š Dynamic Projections**: Any registry key automatically becomes a column
- **ğŸ’¾ Universal Storage**: Efficient Parquet-based sharding with bounded memory
- **ğŸ¯ DeFi-Optimized**: Pre-built support for CL pools, Gauge, and VFAT events
- **âš¡ Smart Filtering**: Fast zero-word filtering and automatic interval splitting
- **ğŸ›¡ï¸ Robust Error Handling**: Automatic retries and graceful failure recovery

## ğŸ—ï¸ Architecture

```
defind/
â”œâ”€â”€ core/           # Data models and constants
â”œâ”€â”€ clients/        # RPC client for Ethereum nodes
â”œâ”€â”€ decoding/       # Event decoding with dynamic projections
â”œâ”€â”€ storage/        # Universal shards and live manifests
â””â”€â”€ orchestration/  # Streaming fetch-decode-write pipeline
```

### Core Components

- **EventLog**: Raw RPC log records
- **UniversalDynColumns**: Dynamic columnar buffer for any projection
- **EventRegistry**: Configurable event decoding specifications
- **ShardAggregator**: Bounded-memory Parquet writer
- **LiveManifest**: Resumable operation tracking

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd define

# Install dependencies
pip install -e .
```

### Basic Usage

```python
from defind.orchestration.orchestrator import fetch_decode_streaming_universal
from defind.decoding.registries import make_clpool_registry
from defind.clients.rpc import RPC

# Setup
rpc = RPC("https://your-ethereum-rpc-url")
registry = make_clpool_registry()

# Fetch and decode data
result = await fetch_decode_streaming_universal(
    rpc=rpc,
    address="0x...",  # Contract address
    topic0s=["0x..."],  # Event signatures
    from_block=18000000,
    to_block=18001000,
    registry=registry,
    out_root="./data",
    # ... other parameters
)
```

## ğŸ“‹ Event Registries

DefInd comes with pre-built registries for common DeFi protocols:

### Concentrated Liquidity Pools
```python
from defind.decoding.registries import make_clpool_registry
registry = make_clpool_registry()
# Supports: Mint, Burn, Collect, CollectFees events
```

### Gauge Events
```python
from defind.decoding.registries import make_gauge_registry
registry = make_gauge_registry()
# Supports: Deposit, Withdraw, ClaimRewards events
```

### VFAT Events
```python
from defind.decoding.registries import make_vfat_registry
registry = make_vfat_registry()
# Supports: Deploy and other VFAT-specific events
```

### Custom Registries
```python
from defind.decoding.specs import EventSpec, TopicFieldSpec, DataFieldSpec

# Define custom event specification
custom_spec = EventSpec(
    topic0="0x...",
    name="CustomEvent",
    topic_fields=[
        TopicFieldSpec("user", 1, "address"),
        TopicFieldSpec("amount", 2, "uint256"),
    ],
    data_fields=[
        DataFieldSpec("timestamp", 0, "uint256"),
    ],
    projection={
        "user_address": "topic.user",
        "token_amount": "topic.amount", 
        "event_time": "data.timestamp",
    }
)
```

## ğŸ”§ Configuration

### Key Parameters

- **`rows_per_shard`**: Number of rows per Parquet file (default: 250,000)
- **`batch_decode_rows`**: Batch size for decoding (default: 50,000)
- **`concurrency`**: Max parallel RPC requests (default: 16)
- **`min_split_span`**: Minimum block range for splitting on failures

### Performance Tuning

```python
# High-throughput configuration
result = await fetch_decode_streaming_universal(
    # ... other params
    rows_per_shard=500_000,     # Larger shards
    batch_decode_rows=100_000,  # Larger batches
    concurrency=32,             # More parallelism
    min_split_span=100,         # Aggressive splitting
)
```

## ğŸ“Š Output Format

DefInd produces Parquet files with a universal schema:

### Base Columns (always present)
- `block_number`: Block number (int64)
- `block_timestamp`: Block timestamp (int64) 
- `tx_hash`: Transaction hash (string)
- `log_index`: Log index within transaction (int32)
- `contract`: Contract address (string)
- `event`: Event name (string)

### Dynamic Columns
Any key in your event registry's `projection` mapping becomes a column automatically, stored as strings for safety with large integers.

## ğŸ› ï¸ Development

### Project Structure
```
src/defind/
â”œâ”€â”€ __init__.py              # Public API exports
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ models.py           # Core data models
â”‚   â””â”€â”€ constants.py        # Event topic constants
â”œâ”€â”€ clients/
â”‚   â””â”€â”€ rpc.py             # Ethereum RPC client
â”œâ”€â”€ decoding/
â”‚   â”œâ”€â”€ specs.py           # Event specifications
â”‚   â”œâ”€â”€ decoder.py         # Generic event decoder
â”‚   â”œâ”€â”€ registries.py      # Pre-built registries
â”‚   â””â”€â”€ utils.py           # Decoding utilities
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ shards.py          # Universal shard writer
â”‚   â””â”€â”€ manifest.py        # Live manifest system
â””â”€â”€ orchestration/
    â”œâ”€â”€ orchestrator.py    # Main streaming pipeline
    â””â”€â”€ utils.py           # Block range utilities
```

### Dependencies
- **httpx**: Async HTTP client for RPC calls
- **pyarrow**: Columnar data processing and Parquet I/O
- **pandas**: Data manipulation and analysis
- **eth-abi**: Ethereum ABI encoding/decoding
- **eth-utils**: Ethereum utility functions
- **rich**: Beautiful terminal output
- **click**: CLI framework

## ğŸ“ˆ Performance

DefInd is optimized for high-throughput data extraction:

- **Concurrent Processing**: Configurable parallelism for RPC requests
- **Bounded Memory**: Streaming processing with configurable batch sizes
- **Efficient Storage**: Columnar Parquet format with compression
- **Smart Resumption**: Skip already-processed ranges automatically
- **Fast Filtering**: Early zero-word detection to skip empty events

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

Built for the DeFi community with â¤ï¸ by [youssefGha98](mailto:youssef@nomiks.io)
